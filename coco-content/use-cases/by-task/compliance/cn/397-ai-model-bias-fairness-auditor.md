# #397 — AI 模型偏差与公平性审计师

**角色**：数据科学家
**行业**：SaaS / 科技
**任务**：合规
**标识**：`ai-model-bias-fairness-auditor`

---

## 简介

模型偏差与公平性已从学术关注演变为监管要求。2024 年，欧盟《人工智能法案》为高风险 AI 系统建立了强制性偏差评估要求。美国《平等信贷机会法》的算法公平性条款正由消费者金融保护局积极执行。纽约市地方法律第 144 号要求雇主对自动化就业决策工具每年进行偏差审计。金融机构面临 SR 11-7 模型风险管理指南，该指南越来越多地将模型风险解释为包含公平性风险。对于构建影响人们的模型（信贷决策、招聘工具、医疗分诊、内容审核、定价）的数据科学家来说，偏差审计已不再是可选项。

技术挑战在于公平性不是单一指标，而是一组可能相互冲突的数学属性。当基础比率不同时，人口平等（各群体间正预测率相等）与均等化胜率（各群体间真正例率和假正例率相等）在数学上是不相容的。统计均等距离、差异性影响比率、平等机会差异、预测均等和组内校准都衡量公平性的不同方面，没有任何模型能同时满足所有标准。这意味着每次公平性分析都需要就哪种公平性标准适用于特定使用场景做出深思熟虑的决定，并提供明确的理由——这是一个同时具有技术性、法律性和伦理性的决策。

大多数数据科学家缺乏算法公平性方面的正式培训。他们理解统计概念，但在以下方面存在困难：为使用场景选择正确的公平性指标、解读 0.74 的差异性影响比率在法律层面的实际含义、以合规团队需要的语言向其传达公平性发现、以满足审计人员的格式记录所采取的缓解步骤，或者了解何时需要升级到法律顾问。结果是许多 ML 团队进行的是即兴的公平性检查，这些检查在监管审查下无法通过。

COCO 充当公平性审计顾问，将技术性公平性分析与符合合规要求的文档相结合。工作流程如下：

1. **描述你的模型和受保护属性。** 指定模型的使用场景、与你所在司法管辖区相关的受保护特征（种族、性别、年龄、国籍），以及每个群体的样本量。
2. **按群体分享性能指标。** 粘贴按受保护属性细分的混淆矩阵、正预测率和准确率指标。
3. **COCO 跨多个标准分析公平性。** 计算差异性影响比率、统计均等差异、均等化胜率差异和组内校准——并解释每项在你的使用场景背景下的含义。
4. **获得面向合规的解读。** COCO 将技术发现映射到相关监管标准，并解释哪些发现在 ECOA、欧盟 AI 法案或其他适用框架下会构成关切。
5. **生成审计文档。** COCO 产出符合合规要求的公平性审计文档，详述方法论、发现、已识别的差异、采取的缓解步骤和残余风险评估。

使用 COCO 进行公平性审计的组织报告，准备公平性审计文档所需时间减少 60%，合规团队对分析严谨性的信心显著提升。

**受益角色：**

- **数据科学家**：在受监管领域（信贷、招聘、医疗、住房）构建模型，需要执行并记录严格的公平性审计
- **ML 团队负责人**：需要确保团队模型在高风险使用场景部署前满足公平性标准
- **合规和法务团队**：需要将技术性公平性分析转化为可以采取行动的监管语言
- **首席 AI 官和 AI 治理团队**：构建企业级负责任 AI 项目

---

## 实用提示词

**提示词 1 — 全面公平性审计**
```
我需要对一个二分类模型进行偏差与公平性审计。背景如下：

模型使用场景：[描述——如"贷款审批模型"、"招聘筛选工具"、"保险定价模型"]
监管背景：[适用法规——如"ECOA/公平住房法"、"欧盟 AI 法案"、"纽约市地方法律第 144 号"]
分析的受保护属性：[列表——如"种族、性别、年龄、国籍"]

按群体划分的模型性能：
[对每个受保护属性及其取值，提供：]
群体：[如"种族：白人"]
- n=[N]，正预测率=[%]，真正例率=[%]，假正例率=[%]，精确率=[%]

群体：[如"种族：黑人"]
- n=[N]，正预测率=[%]，真正例率=[%]，假正例率=[%]，精确率=[%]

[继续列出所有群体]

请执行完整的公平性审计：(1) 计算差异性影响比率、统计均等差异、均等化胜率差异和组内校准，(2) 识别哪些发现在适用框架下达到监管关切的程度，(3) 解释哪些公平性标准对此使用场景最为相关及原因，(4) 建议已识别差异的缓解方案。
```

**提示词 2 — 公平性指标选择**
```
我正在为 [使用场景] 构建 [模型类型]，需要关于应优先选择哪些公平性指标的指导，因为不同指标给出矛盾的信号。

背景：
- 模型预测：[目标——如"贷款违约概率"]
- 正向结果意味着：[如"贷款批准"]
- 不同群体的基础比率不同：[如"A 组历史违约率为 8%，B 组为 14%"]
- 假正例的风险：[描述——如"拒绝有资质的人的贷款申请"]
- 假负例的风险：[描述——如"批准了最终违约的贷款，产生财务损失"]
- 监管框架：[适用]

请解释：(1) 为什么不同的公平性指标在我的案例中给出矛盾的信号，(2) 哪些标准在法律上对我的使用场景最为相关，(3) 哪些标准应作为主要指标与次要指标，(4) 如何向利益相关方传达固有的公平性张力，(5) 我需要什么文档来向审计人员证明指标选择的合理性。
```

**提示词 3 — 偏差缓解策略**
```
我的公平性审计在 [使用场景] 的 [模型类型] 中发现了以下差异：

差异性影响比率（正向结果率比值）：[数值]——[解读，如"低于 0.80 的四分之五规则阈值"]
均等化胜率差异：[数值]
受影响最大的群体：[群体名称] vs. 参考群体 [参考群体]

当前模型：[算法和特征的简要描述]
约束条件：[任何缓解约束——如"不能将受保护属性用作特征"、"必须保持 AUC 高于 0.78"、"不得增加多数群体的假负例率"]

请推荐偏差缓解策略：(1) 预处理选项（数据重新加权、重采样、删除代理特征），(2) 处理中选项（损失函数中的公平性约束），(3) 后处理选项（按群体调整阈值），(4) 各选项之间的权衡，(5) 如何以满足监管机构要求的方式记录缓解措施。
```

**提示词 4 — 代理特征检测**
```
我想识别模型中的潜在代理变量——可能充当受保护属性代理的特征，即使受保护属性本身被排除在外。

受保护属性（从模型中排除）：[列表——如"种族、国籍、宗教"]
模型中包含的特征：[列出所有特征及描述]
模型类型：[算法]
使用场景：[描述]
是否包含地理数据：[是/否]

请分析：(1) 我的哪些特征可能充当每个受保护属性的代理以及原因，(2) 如何测试代理关系是否实际导致差异性影响（相关性分析、置换检验），(3) 我应该考虑删除或转换哪些特征，(4) 对于决定保留的特征，如何记录代理风险。
```

**提示词 5 — 面向监管提交的公平性审计报告**
```
我需要为 [监管目的——如"纽约市地方法律第 144 号合规"、"欧盟 AI 法案符合性评估"、"内部模型风险委员会"] 出具正式公平性审计报告。

模型概述：
- 名称：[模型名称]
- 用途：[功能描述]
- 部署背景：[使用场所/方式]
- 受影响人群：[受影响对象]

审计方法论：
- 使用的数据：[描述]
- 计算的指标：[列表]
- 统计方法：[描述]

发现：
[粘贴公平性分析结果]

采取的缓解步骤：
[列出所做工作]

缓解后的残余差异：
[描述剩余差距]

请生成适用于 [监管目的] 的正式公平性审计报告，包含：执行摘要、模型描述、审计方法论、按受保护特征划分的发现、已采取的缓解措施、残余风险评估和证明语言。
```
