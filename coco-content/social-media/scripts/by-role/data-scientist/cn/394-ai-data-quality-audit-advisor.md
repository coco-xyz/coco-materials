# #394 — AI 数据质量审计顾问 — 视频脚本（中文）

**分类**：数据科学家 / 分析
**核心指标**：模型训练前平均每个数据集发现 3.7 个关键数据问题

---

**场景 1（0:00–0:10）：钩子**
[画面]：数据科学家收到一条 Slack 消息，附带一个 200 列数据集的链接："这是我们上一个模型用的，你应该没问题"
[旁白]："200 列。没有文档。没有数据字典。你得在这个基础上构建一个生产模型。"

---

**场景 2（0:10–0:30）：问题**
[画面]：模型交叉验证表现优秀，然后生产环境 AUC 下跌 30 点；工程师发现时间戳连接几个月来都有差一天的错误；另一个团队发现标签定义 6 个月前改了但没有通知数据团队
[旁白]："73% 的 ML 生产事故可追溯到训练数据中存在数周的数据质量问题。不检查就无法发现——没有系统化的审计框架，大多数团队每个数据集会遗漏 3-5 个关键问题。"

---

**场景 3（0:30–0:50）：COCO 实操**
[画面]：将数据集模式和 pandas-profiling 输出粘贴给 COCO，收到结构化审计清单——完整性、泄漏风险、标签质量、分布健康度——然后 COCO 标记一个提示数据采集 bug 的可疑空值模式
[旁白]："向 COCO 描述数据集并粘贴分析输出。COCO 为你的特定 ML 任务生成自定义审计清单——涵盖泄漏风险、标签质量、分布漂移和偏差指标。系统地逐项检查，分享发现，COCO 帮你解读模糊的结果。"

---

**场景 4（0:50–1:00）：结果**
[画面]：与工程团队共享结构化数据质量报告，3 个关键 bug 在模型训练开始前被修复，合规官批准审计文档
[旁白]："平均每个数据集发现 3.7 个关键问题。干净的数据，可信赖的模型。立即前往 coco.xyz 体验 COCO。"
