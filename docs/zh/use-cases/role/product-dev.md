# 产品与研发

AI驱动的开发者、DevOps工程师、技术负责人和产品经理用例。

## 1. AI代码审查

> 自动审查每个PR：Bug、安全漏洞、性能问题——15分钟出完整报告。

::: details ▶ 观看演示视频

<video controls width="100%" style="max-width: 720px; border-radius: 8px; margin: 0.5rem 0 1rem;">
  <source src="/videos/cn/005-ai-code-reviewer.mp4" type="video/mp4">
</video>

:::

::: details 痛点与解决方案

**痛点：Code Review正在拖垮你的工程效率**

Code review是软件工程中最重要的质量关卡之一——也是最大的瓶颈之一。Google和微软的研究显示，开发者20-30%的工作时间花在审查别人的代码上。对于高级工程师，这个比例往往更高。结果是一个痛苦的悖论：最有资格做review的人，恰恰是你最需要他们写代码的人。

连锁反应很严重。慢review阻塞合并。阻塞的合并制造集成冲突。开发者在写代码和review代码之间来回切换，深度工作被彻底破坏。而当review因为队列压力被匆忙完成时，bug就溜了进去——这恰恰是这个流程要防止的结果。

**COCO如何解决**

COCO的AI Code Reviewer直接集成到你现有的Git工作流（GitHub、GitLab、Bitbucket），充当一个随时在线的第一轮审查员。完整工作流程：

1. **自动触发**：PR创建或更新时，COCO自动介入，无需手动操作。

2. **多维度分析**：COCO同时从多个维度审查diff：
   - **安全性**：SQL注入、XSS、硬编码密钥、不安全依赖、认证绕过
   - **性能**：N+1查询、不必要的重渲染、内存泄漏、无索引数据库查询
   - **逻辑**：边界情况、空指针风险、竞态条件、差一错误
   - **规范**：团队编码标准、命名规范、文件结构
   - **架构**：设计模式违规、耦合问题、关注点分离

3. **上下文评论**：COCO在需要关注的具体代码行上发布内联评论，解释问题原因并提供修复建议。它理解上下文——不会把一个明显是HTTP状态码的"魔法数字"标记出来。

4. **学习你的代码库**：COCO会索引你仓库的模式、惯例和架构。随着时间推移，它的审查越来越符合你团队的具体标准，而不仅仅是通用最佳实践。

5. **严重性分级**：问题分为严重（必须修复）、警告（建议修复）和建议（锦上添花）。开发者可以有效地按优先级处理，而不是面对一个扁平的列表。

6. **人工审查路由**：COCO第一轮审查完成后，PR被路由给最合适的人工审查者，基于代码所有权、专业领域和当前工作量。人工审查者看到COCO的分析结果，只需聚焦于架构决策、业务逻辑正确性和设计权衡。

:::

::: details 量化结果与受益角色

**可量化的结果**

- PR审查周期平均**缩短68%**
- 合并前发现的bug**增加73%**
- 到达生产环境的安全漏洞**减少85%**
- 高级工程师每周**释放11+小时**
- review相关的Slack消息和上下文切换**减少40%**

**受益角色**

- **技术主管**：在不牺牲质量的前提下加速交付
- **高级工程师**：从重复性review工作中解放，专注架构和指导
- **初级工程师**：更快的反馈循环加速成长，减少"等review"的阻塞
- **安全团队**：每个PR都有一致的安全扫描，而不是定期审计

:::

::: details 实用提示词

**提示词 1: 安全专项代码审查**
```
审查这个Pull Request的安全漏洞，重点关注：
1. SQL注入或NoSQL注入风险
2. 跨站脚本攻击（XSS）向量
3. 硬编码的密钥、API Key或凭据
4. 不安全的反序列化
5. 认证/授权绕过风险
6. 不安全的直接对象引用

对每个发现的问题，说明攻击向量、严重性（严重/高/中/低），并提供安全的代码修复方案。以下是diff：

[粘贴PR diff]
```

**提示词 2: 数据库密集型代码的性能审查**
```
分析这段代码变更的性能问题，具体关注：
1. N+1查询模式（识别每个实例）
2. 新查询缺少的数据库索引
3. 可能返回海量结果集的无界查询
4. 可以批量操作替代循环的机会
5. 不必要的数据加载（查询了未使用的列）

我们的技术栈是[Python/Django + PostgreSQL / Node.js + MongoDB / 等]。当前表规模：users（约200万行），orders（约1500万行），products（约50万行）。

对每个问题提供优化方案和预期性能提升。以下是代码：

[粘贴代码]
```

**提示词 3: 符合团队规范的完整PR审查**
```
以团队高级工程师的身份审查这个PR。我们的规范：
- 语言：TypeScript严格模式
- 风格：Airbnb ESLint配置，Prettier默认设置
- 测试：新代码最低80%分支覆盖率
- 模式：数据访问使用Repository模式，依赖注入
- 错误处理：自定义错误类，禁止裸catch块
- 命名：变量camelCase，类型PascalCase，常量SCREAMING_SNAKE

审查要点：逻辑错误、边界情况、风格违规、测试覆盖缺口、架构问题。每个发现归类为[必须修复]、[建议修复]或[优化建议]。

PR标题：{标题}
PR描述：{描述}
Diff：
[粘贴diff]
```

**提示词 4: 遗留代码重构审查**
```
这个PR重构了一个遗留模块。请审查：
1. 是否有可能破坏现有功能的行为变更？
2. 重构是否完整，是否有遗留的旧模式？
3. 是否有增加复杂性但没有明确收益的新抽象？
4. 公共API的向后兼容性是否维持？
5. 是否有充分的测试覆盖重构后的路径？

原始代码行为概述：[简要描述]
Diff：
[粘贴diff]
```

**提示词 5: 面向技术经理的PR总结**
```
为非技术背景的技术经理生成这个PR的执行摘要，包括：
1. 用通俗语言说明这个变更做了什么（2-3句话）
2. 风险评估（低/中/高）及理由
3. 需要人工重点审查的区域
4. 如果出问题的影响范围评估
5. 回滚复杂度（简单回滚 vs 需要数据迁移）

PR信息：
[粘贴PR详情和diff]
```

:::

## 2. AI测试生成

> 读取源码，30分钟生成包含边界条件的完整测试。覆盖率从34%提升到89%。

::: details ▶ 观看演示视频

<video controls width="100%" style="max-width: 720px; border-radius: 8px; margin: 0.5rem 0 1rem;">
  <source src="/videos/en/006-ai-test-generator.mp4" type="video/mp4">
</video>

:::

::: details 痛点与解决方案

**痛点：永远还不清的测试覆盖率债务**

每个工程团队都有测试覆盖率目标，几乎没有团队能持续达标。经济账很残酷：为一个函数写完整测试所需时间是写函数本身的2-5倍。边界情况进一步翻倍。而当截止日期到来时，测试是第一个被砍掉的——"以后再补"变成了永恒状态。

后果在悄悄累积。低测试覆盖率意味着每次部署都是赌博。重构变得令人恐惧，因为你无法信任安全网。Bug回归成为常态。开发者对代码库失去信心，进一步拖慢开发速度。这是一个向下的螺旋。

手动QA也无法扩展。一个QA工程师手动编写测试，每天能产出10-20个高质量测试。对于一个拥有数千个函数和数百个API端点的成熟代码库，追赶在数学上是不可能的。

**COCO如何解决**

COCO的AI Test Generator不只是创建样板测试。它对你的代码进行深度分析，生成真正能捕获bug的测试。以下是具体流程：

1. **代码库分析**：COCO扫描整个代码仓库，理解架构、依赖关系、数据模型和现有测试模式。它映射每个函数、方法和端点，识别哪些路径有测试覆盖，哪些没有。

2. **基于风险的优先级生成**：COCO不会随机生成测试，而是按风险优先级排序：
   - 处理金钱、认证或用户数据的代码路径
   - 高圈复杂度的函数（更多分支=更多风险）
   - 最近修改的代码（统计上bug最可能出现的地方）
   - 服务间的集成点

3. **智能边界情况发现**：COCO分析每个函数的参数、类型和行为，生成边界用例：
   - Null/undefined/空输入
   - 边界值（0、-1、MAX_INT、空数组）
   - 类型转换陷阱
   - 并发访问场景
   - 时区和区域设置相关行为
   - 错误传播路径

4. **模式匹配**：COCO读取你现有的测试并匹配：
   - 测试框架和断言库（Jest、Vitest、pytest、JUnit等）
   - Fixture和工厂模式
   - Mock/Stub策略
   - 命名规范
   - 文件组织结构

5. **测试质量保证**：每个生成的测试都是：
   - 确定性的（没有因随机数据或时序导致的不稳定测试）
   - 独立的（可以任意顺序运行）
   - 快速的（默认mock外部依赖）
   - 可读的（清晰的测试名称描述被验证的行为）

6. **持续缺口分析**：初始生成后，COCO监控代码变更，自动为修改的代码建议新测试，确保覆盖率不退化。

:::

::: details 量化结果与受益角色

**可量化的结果**

- 6周内覆盖率**从34%提升到78%**（中型代码库的典型结果）
- 生成测试**89%首次运行通过**
- 生产环境bug回归率**降低60%**
- 新功能达到覆盖率标准的时间**缩短85%**
- 每季度测试编写**节省450+开发者小时**
- 首次运行失败的测试中，**73%发现了真实bug**

**受益角色**

- **开发者**：自信发版，无惧重构
- **QA工程师**：专注探索性测试和复杂场景，而非编写样板代码
- **技术经理**：可量化的质量指标可供汇报，生产环境bug导致的紧急救火更少
- **产品团队**：重构不被缺失的测试阻塞，功能交付更快

:::

::: details 实用提示词

**提示词 1: 为未测试模块生成测试**
```
分析以下模块并生成全面的单元测试。我们的技术栈使用[Jest/Vitest/pytest]，采用[describe/it/test]风格。

要求：
- 覆盖所有公共方法
- 包含正常路径、错误情况和边界情况
- Mock外部依赖（数据库、API调用、文件系统）
- 使用描述性的测试名称，遵循模式："当[条件]时，应该[预期行为]"
- 匹配我们现有的fixture模式（参考下面的示例测试）

待测试模块：
[粘贴模块代码]

参考的现有测试示例：
[粘贴项目中一个现有测试文件]
```

**提示词 2: 边界测试用例发现**
```
对以下函数，识别所有可能的边界情况并为每个生成测试。考虑：
- 输入边界（最小值、最大值、零、负数、空、null、undefined）
- 类型转换风险
- 并发执行场景
- 状态变异副作用
- 依赖的错误传播
- 时区/区域设置敏感行为
- Unicode和特殊字符处理

函数：
[粘贴函数代码]

依赖/上下文：
[粘贴相关类型定义或接口]
```

**提示词 3: 集成测试套件生成**
```
为我们的[REST API / GraphQL API]端点生成集成测试。

端点：[HTTP方法] [路径]
请求体Schema：[粘贴schema]
响应Schema：[粘贴schema]
认证方式：[Bearer token / API key / Session]
涉及的数据库模型：[列出模型]

生成覆盖以下场景的测试：
1. 有效数据的成功请求
2. 校验错误（缺少必填字段、无效类型、边界值）
3. 认证/授权失败
4. 并发请求处理
5. 数据库约束违规
6. 速率限制行为
7. 响应格式和状态码验证

使用[supertest/httpx/RestAssured]发送HTTP请求，[factory-bot/faker]生成测试数据。
```

**提示词 4: 基于Bug报告的回归测试**
```
一个bug已被报告并修复。生成回归测试确保此bug永不复发。

Bug描述：[描述bug]
根本原因：[解释原因]
已应用的修复：[描述或粘贴修复代码]
受影响的代码：
[粘贴相关代码]

生成的测试应该：
1. 重现确切的bug场景（应用修复后应该通过）
2. 覆盖可能导致类似bug的相关边界情况
3. 测试修复周围的边界条件
4. 验证修复没有破坏相关功能
```

**提示词 5: 测试覆盖缺口分析**
```
以下是我们当前的测试文件和它测试的源模块。分析哪些没有被覆盖，并生成缺失的测试。

源模块：
[粘贴源代码]

当前测试文件：
[粘贴现有测试]

识别：
1. 未测试的函数/方法
2. 未测试的分支（if/else路径、switch分支、try/catch）
3. 已测试函数的缺失边界情况
4. 缺失的错误场景测试
5. 函数间缺失的集成测试

只生成缺失的测试，不要重复已有的覆盖。
```

:::

## 3. AI部署监控

> 实时监控每次部署，90秒检测异常，自动回滚。MTTR从47分钟降至2分钟。

::: details ▶ 观看演示视频

<video controls width="100%" style="max-width: 720px; border-radius: 8px; margin: 0.5rem 0 1rem;">
  <source src="/videos/en/007-ai-deploy-monitor.mp4" type="video/mp4">
</video>

:::

::: details 痛点与解决方案

**痛点：部署是你最大的事故来源**

DORA（DevOps研究与评估）的研究持续表明，部署是生产事故的最大单一来源。讽刺的是：你发布越快（每个业务都要求的），你制造的事故越多。大多数团队的应对方式要么是放慢部署（损害速度），要么是接受更高的事故率（损害可靠性）。

核心问题不是部署本身——而是检测和响应的时间差。平均而言，检测到部署引起的回归需要15-45分钟，诊断根因再需要10-30分钟，执行回滚还要5-15分钟。在这个窗口期间，用户在受苦，收入在流失，信任在瓦解。

现有监控工具很强大但是被动的。它们收集数据，基于静态阈值触发告警。它们不理解在部署后恰好3分钟开始的延迟飙升很可能是由那次部署引起的。这种关联——人类看时间线一目了然——每次都需要手动调查。

**COCO如何解决**

COCO的AI Deploy Monitor作为智能层叠加在你现有的监控基础设施之上（Datadog、Prometheus/Grafana、CloudWatch、New Relic等）。它不替代你的工具——它让它们变得主动。

1. **部署感知监控**：COCO接入你的CI/CD流水线（GitHub Actions、GitLab CI、Jenkins、ArgoCD）。当部署开始时，COCO自动进入强化监控模式，捕获部署前窗口的基线指标并监控偏差。

2. **多信号异常检测**：COCO同时监控多个维度的信号：
   - 应用层：错误率、延迟百分位（p50、p95、p99）、吞吐量
   - 基础设施：CPU、内存、磁盘I/O、网络、容器重启
   - 业务层：交易完成率、购物车放弃率、API成功率
   - 依赖层：数据库查询时间、缓存命中率、外部API延迟

3. **因果关联**：检测到异常时，COCO不只是告警——它将异常与部署中的具体变更进行关联。分析diff，识别哪些服务被修改，将异常映射到最可能的根因。

4. **自动化响应层级**：
   - **一级（警告）**：检测到细微异常。通知团队并附带分析。不采取行动。
   - **二级（自动暂停）**：检测到显著回归。暂停金丝雀发布。等待人工决策。
   - **三级（自动回滚）**：严重回归（错误率>阈值，延迟>SLA）。自动回滚并通知。

5. **部署后分析**：每次部署后（无论成功与否），COCO生成部署健康报告：
   - 部署前后指标对比
   - 检测到的异常及其解决方式
   - 随时间推移的性能回归趋势
   - 提升部署安全性的建议

6. **事件时间线构建**：当出问题时，COCO自动构建详细的事件时间线：部署了什么、指标何时开始偏离、哪些用户受影响、根因是什么、采取了哪些操作。这省去了数小时的事后调查。

:::

::: details 量化结果与受益角色

**可量化的结果**

- **平均检测时间（MTTD）**：从23分钟缩短到94秒
- **平均回滚时间（MTTR）**：从15分钟缩短到3分钟以内
- **部署引起的客户侧事故**：减少91%
- **值班工程师告警疲劳**：减少65%（更少的误报）
- **事后复盘准备时间**：从4小时缩短到30分钟

**受益角色**

- **SRE/DevOps团队**：睡得更好，更少的告警，更快的事故解决
- **值班工程师**：清晰的根因分析，而不是凌晨3点的手动排查
- **技术经理**：更快发版而不增加事故率
- **业务干系人**：更高的可用性，更少的客户投诉，保护了收入

:::

::: details 实用提示词

**提示词 1: 部署后健康检查分析**
```
分析以下部署指标，判断此次部署是否健康或需要回滚。

部署时间：[时间]
服务名：[服务名]
变更内容：[简要描述部署了什么]

部署前基线（最近30分钟）：
- 错误率：[X]%
- p99延迟：[X]ms
- CPU利用率：[X]%
- 内存：[X]%
- 请求/秒：[X]

部署后（最近15分钟）：
- 错误率：[X]%
- p99延迟：[X]ms
- CPU利用率：[X]%
- 内存：[X]%
- 请求/秒：[X]

错误日志样本：
[粘贴近期错误日志]

请提供：健康判定、风险评估、异常时的根因假设、建议操作（继续/观察/回滚）。
```

**提示词 2: 事故根因分析**
```
部署后发生了事故。帮我构建根因分析报告。

时间线：
- 部署开始：[时间]
- 部署完成：[时间]
- 首次检测到异常：[时间]
- 告警触发：[时间]
- 发起回滚：[时间]
- 确认恢复：[时间]

部署变更（diff摘要）：
[粘贴关键变更]

受影响的指标：
[粘贴指标数据或截图描述]

错误样本：
[粘贴代表性错误]

生成结构化RCA，包括：
1. 事故概述（发生了什么、影响范围、持续时间）
2. 根本原因（具体是什么导致了问题）
3. 促成因素（什么让情况变得更糟）
4. 时间线分析（在哪里浪费了时间）
5. 行动项（防止复发、改进检测、缩小影响面）
```

**提示词 3: 部署操作手册生成**
```
为我们的[服务名]生成部署操作手册：

架构：[描述服务架构]
依赖：[列出上下游服务]
数据库迁移：[是/否，如有请描述]
功能开关：[列出要切换的功能开关]
预期流量：[当前请求/秒]
部署策略：[滚动/蓝绿/金丝雀，X%递增]

包含：
1. 部署前检查清单（部署前需要验证什么）
2. 发布过程中需要监控的关键指标（附具体阈值）
3. 部署后要执行的冒烟测试命令
4. 回滚流程（分步骤说明）
5. 沟通计划（通知谁、什么时候通知）
6. 已知风险和缓解措施
```

**提示词 4: 告警阈值优化**
```
我们当前的告警产生太多误报。帮助优化阈值。

服务：[服务名]
当前告警及其阈值：
[列出每个告警及当前阈值]

最近30天告警历史：
- 触发告警总数：[X]
- 真阳性（实际事故）：[X]
- 假阳性：[X]
- 部署期间的告警：[X]

正常流量模式：
- 峰值时段：[时间段]
- 低峰基线：[指标]
- 已知流量尖峰：[例如：午夜批处理任务]

推荐新阈值，将误报减少至少50%的同时保持对真实事故的检测能力。考虑基于时段的动态阈值。
```

:::

## 4. AI API文档编写

> 从代码库自动生成并同步API文档，多语言示例，零偏差。

::: details ▶ 观看演示视频

<video controls width="100%" style="max-width: 720px; border-radius: 8px; margin: 0.5rem 0 1rem;">
  <source src="/videos/en/008-ai-api-doc-writer.mp4" type="video/mp4">
</video>

:::

::: details 痛点与解决方案

**痛点：文档漂移正在悄悄毁掉你的开发者体验**

API文档是每个接入开发者了解你产品的第一道门。当它出错时，代价高昂：开发者花数小时对着错误的文档debug，提交支持工单，有时直接放弃你的API转向文档更好的竞品。

根本原因是结构性的。在大多数工程工作流中，文档是二等公民。初始开发时写一次，然后随着代码演进逐渐偏离。参数类型变了、新的必填字段加了、错误码引入了——但文档落后了。文档没有CI/CD，没有自动化测试来捕获文档和代码的分歧。

技术写作者——如果公司有的话——永远在追赶。工程师修改响应格式时他们不在场。他们是在客户投诉时才知道的。这个循环每个sprint重复一次。

**COCO如何解决**

COCO的AI API Doc Writer将文档视为与代码库自动同步的活文档。

1. **代码优先的文档**：COCO分析你的实际实现——路由处理器、中间件、验证schema、类型定义、数据库模型——从唯一真实来源生成文档。不再需要手动从代码抄参数名到文档。

2. **OpenAPI/Swagger生成**：COCO自动从代码库生成或更新OpenAPI 3.0规范，包括：
   - 所有端点的HTTP方法和路径
   - 请求体schema，含类型、必填字段和验证规则
   - 所有状态码的响应schema（200、400、401、404、500）
   - 每个端点的认证要求
   - 限流信息
   - 弃用通知

3. **丰富的端点文档**：为每个端点，COCO产出：
   - 人类可读的端点功能描述和使用场景
   - 参数文档，含类型、约束和默认值
   - 覆盖常见场景的多个请求/响应示例
   - 错误响应目录，含原因和解决步骤
   - 相关端点和工作流上下文

4. **多语言代码示例**：COCO用你用户的编程语言生成可运行的代码示例：
   - cURL（通用）
   - Python（requests + 你的SDK如有）
   - JavaScript/TypeScript（fetch + Node.js）
   - 按需支持Go、Ruby、Java、PHP
   - 每个示例包含正确的认证、错误处理和常见模式

5. **偏差检测**：COCO持续对比现有文档和当前代码库，标记：
   - 未文档化的新端点
   - 被添加、移除或更改类型的参数
   - 不再匹配文档schema的响应格式
   - 仍显示为活跃的已弃用端点
   - 未反映在文档中的认证变更

6. **开发者指南生成**：除了参考文档，COCO还生成概念指南：
   - 入门/快速开始教程
   - 认证和授权指南
   - 分页和过滤模式
   - Webhook集成指南
   - 破坏性变更时的迁移指南

:::

::: details 量化结果与受益角色

**可量化的结果**

- 所有端点**100%文档覆盖率**（对比行业典型的60-70%）
- **零文档偏差**——文档始终匹配当前API行为
- 开发者支持工单**减少34%**
- 新接入者首次API调用时间**缩短75%**
- 技术写作者文档维护工作量**减少90%**
- **开发者NPS提升**：部署准确文档后平均+18分

**受益角色**

- **外部开发者/合作伙伴**：准确、始终最新的文档减少接入时间和挫败感
- **技术写作者**：从维护参考文档中解放，专注于教程、指南和开发者教育
- **开发者关系**：更好的文档=更多采用，更少的支持升级
- **工程团队**：不再有"别忘了更新文档"的PR评论后遗症

:::

::: details 实用提示词

**提示词 1: 生成API端点文档**
```
为以下端点实现生成完整的API文档。包含：
1. 端点描述（功能、使用场景）
2. HTTP方法和路径
3. 认证要求
4. 请求参数（路径、查询、请求头、请求体），含类型、必填/可选、约束
5. 所有状态码的响应schema（成功+所有错误情况）
6. 两个请求/响应示例（一个成功，一个错误）
7. 限流详情（如适用）
8. 相关端点

代码实现：
[粘贴路由处理器、验证schema和相关模型代码]

输出格式：适合开发者文档网站的Markdown。
```

**提示词 2: 生成OpenAPI 3.0规范**
```
为以下API端点生成OpenAPI 3.0 YAML规范。分析代码以提取：
- 路径和HTTP方法
- 请求体schema（从验证规则和类型定义推导）
- 响应schema（从序列化代码和类型定义推导）
- 认证方案（Bearer、API Key、OAuth2）
- 错误响应schema
- 公共组件（可复用的schema、参数、响应）

包含恰当的描述、示例和用于组织的标签。

源代码：
[粘贴路由文件和相关模型/类型]

需包含的端点：
[如果不是全部，列出端点路径]
```

**提示词 3: 生成多语言代码示例**
```
为以下API端点生成可运行的代码示例，使用以下语言：cURL、Python、JavaScript（Node.js）和Go。

端点：[HTTP方法] [路径]
认证方式：Authorization请求头中的Bearer token
请求体：[粘贴schema或示例]
基础URL：https://api.example.com/v1

每个示例应该：
- 包含正确的认证请求头
- 处理响应（解析JSON，检查状态码）
- 包含基本的错误处理
- 展示请求和预期响应
- 使用语言的标准HTTP库（不引入不必要的依赖）
- 包含解释每个步骤的注释
```

**提示词 4: 文档偏差审计**
```
对比以下API文档和实际实现，识别差异。

当前文档：
[粘贴现有API文档或OpenAPI规范]

当前实现：
[粘贴实际的路由处理器、验证schema和模型]

报告：
1. 代码中存在但文档中缺失的端点
2. 文档中存在但代码中已移除的端点
3. 参数不匹配（名称、类型、必填状态）
4. 响应schema差异
5. 缺失的错误码/响应
6. 过时的示例
7. 认证要求变更

将每个差异按优先级分类：严重（将导致接入失败）、高（将导致困惑）、低（外观/细微问题）。
```

**提示词 5: 开发者快速入门指南**
```
为我们的API编写开发者快速入门指南，让新用户在10分钟内完成从零到第一次成功的API调用。

API概述：[简要描述API功能]
认证方式：[如何获取API密钥/令牌]
基础URL：[URL]
最常见的首次调用端点：[新用户通常首先调用的端点]

指南应包含：
1. 前置条件（账户设置、获取API密钥）
2. 发起第一个请求（含cURL示例）
3. 理解响应
4. 常见的下一步操作（2-3个后续端点）
5. 错误排查（新用户最常遇到的3个错误）
6. 完整文档链接

用友好、清晰的语调编写。假设读者是开发者但从未使用过这个特定API。
```

:::

## 5. AI调试助手

> 粘贴错误日志，AI从症状追溯到根因，提供可直接应用的修复diff。

::: details ▶ 观看演示视频

<video controls width="100%" style="max-width: 720px; border-radius: 8px; margin: 0.5rem 0 1rem;">
  <source src="/videos/en/009-ai-debug-assistant.mp4" type="video/mp4">
</video>

:::

::: details 痛点与解决方案

**痛点：Debug是工程效率最大的隐形税**

Debug是工程时间的黑洞。剑桥大学的研究估计，开发者50%的编程时间花在发现和修复bug上。其中，大部分时间花在诊断上——而不是修复本身。修复通常只有一行。找到那一行要花好几个小时。

核心问题是知识的不对称。错误信息告诉你发生了什么，但不说为什么。堆栈追踪显示崩溃在哪里，但不指向上游原因。要弥补这个鸿沟，开发者需要在脑海中维持整个系统的上下文：数据如何在服务之间流动、每个函数有什么假设、最近改了什么、什么可能级联导致了这个特定的故障。

高级开发者debug更快，因为他们从经验中积累了这些上下文。但即使是他们，在bug跨越服务边界、涉及时序相关的行为，或者源于几周前别人的一个修改时，也会碰壁。而初级开发者？他们经常被一个高级工程师20分钟就能解决的bug卡一整天——因为他们缺少上下文心智模型。

**COCO如何解决**

COCO的AI Debug Assistant作为一个高级debug伙伴，读过你的整个代码库，理解你的架构，能将错误与近期变更关联起来。

1. **上下文错误分析**：当你粘贴一个错误、堆栈追踪或非预期行为描述时，COCO不只是读错误信息。它：
   - 解析完整的堆栈追踪以理解执行路径
   - 读取堆栈中引用的相关源文件的具体行
   - 检查错误位置周围的类型、接口和数据流
   - 检查最近的git提交，看错误位置附近是否有变更
   - 在你的错误追踪系统中搜索类似的历史错误

2. **根因链**：COCO从症状反向追踪因果链到根本原因。例如：
   - **症状**："Cannot read property 'email' of undefined"
   - **直接原因**：第47行的`user`对象是undefined
   - **上游原因**：`findUserById`返回了null，因为查询使用的是`user_id`但列在迁移#283中被重命名为`account_id`
   - **根本原因**：迁移已执行但ORM模型没有更新列名映射

3. **带diff的修复建议**：COCO不只是解释问题——它生成可直接应用的代码diff。考虑因素包括：
   - 最小化修改以修复bug而不产生副作用
   - 修复应该包含空值检查、迁移、schema变更还是配置更新
   - 可能有相同bug模式的相关代码

4. **性能调试**：除了错误，COCO还帮助诊断性能问题：
   - 从执行计划识别慢SQL查询
   - 在ORM代码中发现N+1查询模式
   - 从堆快照检测内存泄漏
   - 通过追踪请求生命周期分析API响应慢的原因

5. **日志分析**：COCO可以消化日志文件：
   - 从冗长日志中过滤信号和噪声
   - 在数千行日志中识别模式和异常
   - 跨多个服务关联时间戳以重建请求流
   - 发现故障前的错误模式前兆

6. **知识积累**：每次debug会话都让COCO更了解你的系统。随时间推移，它构建起以下模型：
   - 你代码库中常见的故障模式
   - 哪些组件脆弱以及为什么
   - bug中的重复模式（例如"每次缓存TTL配置变更，这三个端点就会挂"）

:::

::: details 量化结果与受益角色

**可量化的结果**

- Debug时间**从每周9.2小时降至3.4小时**（减少63%）
- Bug解决时间（MTTR）**缩短58%**
- 初级开发者生产力**提升40%**（通过AI辅助学习加速成长）
- 重复性bug模式被识别并系统性消除，bug复发率**降低45%**
- 每个开发者每周**5.8小时回归到功能开发**

**受益角色**

- **所有开发者**：更快的诊断意味着更少的挫败感和更多的心流时间
- **初级开发者**：AI结对debug加速学习，减少对高级mentor的依赖
- **技术经理**：可量化的debug开销降低，更多时间用于功能开发
- **值班工程师**：故障期间更快的事故诊断

:::

::: details 实用提示词

**提示词 1: 带完整上下文的错误诊断**
```
帮我调试这个错误。以下是所有上下文：

错误信息和堆栈追踪：
[粘贴完整错误输出]

相关源代码（堆栈追踪中引用的文件）：
[粘贴代码]

错误发生时我在做什么：
[描述触发错误的操作/请求]

最近变更（最近几个涉及此区域的提交）：
[粘贴git日志或描述变更]

环境：[Node.js 20 / Python 3.12 / 等] 运行在 [本地 / 预发布 / 生产]

从症状追踪到根源的因果链。然后以代码diff的形式提供修复方案。
```

**提示词 2: 性能问题诊断**
```
这个API端点响应缓慢。帮我找到瓶颈。

端点：[HTTP方法] [路径]
平均响应时间：[X]ms（预期：[Y]ms）
缓慢条件：[所有情况 / 高负载 / 特定请求]

以下是处理器代码及其调用的所有函数：
[粘贴代码，包括数据库查询、外部API调用等]

数据库查询执行计划（如有）：
[粘贴EXPLAIN输出]

一个慢请求的应用日志：
[粘贴带时间戳的日志]

识别：
1. 导致缓慢的具体瓶颈
2. 为什么慢（算法复杂度、缺少索引、同步阻塞等）
3. 优化后的代码及预期改进
```

**提示词 3: 重现和修复间歇性Bug**
```
我有一个无法稳定重现的间歇性bug。帮我缩小范围。

症状：[描述什么出了问题]
频率：[大约X%的时间发生 / 只在特定条件下]
开始时间：[大约日期或部署版本]

我已经尝试过：
[列出已执行的调试步骤]

相关代码：
[粘贴bug表现所在的代码区域]

失败实例的日志：
[粘贴]

成功实例的日志（相同操作）：
[粘贴]

分析失败和成功情况之间的差异。识别可能原因（竞态条件、时序、数据相关、环境相关）。建议重现策略和修复方案。
```

**提示词 4: 内存泄漏调查**
```
我们的[Node.js/Python/Java]服务内存使用量持续增长，直到每[X小时]OOM一次。

当前内存概况：
- 启动时：[X]MB
- 1小时后：[X]MB
- 4小时后：[X]MB
- OOM阈值：[X]MB

堆快照摘要（如有）：
[粘贴顶部保留对象/大小]

怀疑的代码区域：
[粘贴处理最多数据或创建最多对象的代码]

可能引入泄漏的最近变更：
[粘贴或描述]

分析常见泄漏模式：未移除的事件监听器、闭包保留引用、无淘汰策略的增长缓存、未正确关闭的流、阻止GC的循环引用。提供具体的修复建议。
```

**提示词 5: 基于日志的事故调查**
```
发生了一次事故，我需要从日志中理解发生了什么。日志来自[数量]个服务，时间窗口为[X分钟]。

服务A日志：
[粘贴]

服务B日志：
[粘贴]

服务C日志：
[粘贴]

时间线背景：
- 事故报告时间：[时间]
- 涉及的服务：[列表]
- 用户影响：[描述]

跨服务关联日志，重建：
1. 导致事故的事件序列
2. 第一个故障点
3. 故障如何在服务间传播
4. 根本原因
5. 从影响开始到恢复的时间线
```

:::

