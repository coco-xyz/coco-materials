# #390 — AI 模型评估报告生成器 — 视频脚本（中文）

**分类**：数据科学家 / 报告生成
**核心指标**：每份评估报告从 4.2 小时缩短至 35 分钟

---

**场景 1（0:00–0:10）：钩子**
[画面]：数据科学家盯着满屏 scikit-learn 指标输出，旁边是一个空白的 Confluence 页面，时钟显示晚上 6:47
[旁白]："你的模型 AUC 达到了 94%。现在你要向产品经理、合规团队和 CTO 解释这究竟意味着什么——祝你好运。"

---

**场景 2（0:10–0:30）：问题**
[画面]：只有一个准确率数字的 PPT、Slack 里在问"假负例率到底是多少"的消息串、数据科学家手动把混淆矩阵数字复制粘贴进文档
[旁白]："写一份完整的模型评估报告需要 4 小时以上——指标分析、校准检验、阈值分析、业务影响、风险标记。大多数团队跳过了一半。然后模型上线了，没人知道它为什么在生产环境中失效。"

---

**场景 3（0:30–0:50）：COCO 实操**
[画面]：将 classification_report 和 MLflow 元数据粘贴给 COCO，COCO 生成结构化章节——执行摘要、分类别明细、阈值建议、风险标记——一次响应全部完成
[旁白]："把原始输出粘贴给 COCO：sklearn 报告、AUC 曲线、实验配置。COCO 解读每项指标，将精确率-召回率转化为业务成本语言，标记校准问题，撰写完整报告——从执行摘要到合规证明语言，一步到位。"

---

**场景 4（0:50–1:00）：结果**
[画面]：精心排版的模型评估文档在 Notion 中共享，产品经理评论"终于理解召回率对我们意味着什么了"，模型评审会议从 90 分钟缩短到 20 分钟
[旁白]："从 4 小时到 35 分钟。每次都是完整报告。立即前往 coco.xyz 体验 COCO。"
