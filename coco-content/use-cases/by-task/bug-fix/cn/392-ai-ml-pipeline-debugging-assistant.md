# #392 — AI ML 流水线调试助手

**角色**：数据科学家
**行业**：SaaS / 科技
**任务**：问题修复
**标识**：`ai-ml-pipeline-debugging-assistant`

---

## 简介

ML 流水线的故障方式与普通软件 bug 在本质上截然不同。标准软件 bug 会产生清晰的错误信息，直接指向特定代码行。而 ML 流水线 bug 的表现可能是：训练损失在第 3 轮后莫名其妙地停止下降、模型训练准确率达到 99% 但验证准确率只有 51%、批量归一化层仅在特定 GPU 上导致 NaN 损失，或者 Airflow DAG 由于在错误键上进行连接而悄无声息地破坏数据，产生看起来合理实则完全错误的训练数据。故障模式往往模糊，复现通常具有非确定性，根本原因可能隐藏在数据预处理、特征工程、模型架构、训练循环配置、硬件和编排系统等任何层面。

诊断 ML 流水线问题需要同时推理统计学、软件工程、线性代数和分布式系统——即使是经验丰富的从业者也觉得挑战巨大。数据科学家在调试 PyTorch Transformer 的梯度消失问题时，必须同时考虑：学习率调度、权重初始化方案、批量大小与批量归一化的交互、梯度裁剪阈值、层归一化位置、混合精度训练的交互影响，以及损失函数是否数值稳定。任何一项都可能是罪魁祸首。系统性调试需要有条理的核查清单、领域特定的模式识别能力，以及推断这些变量如何相互影响的能力——这些知识需要多年积累。

调试延误的成本以 GPU 小时和日历时间来衡量。一家深度学习初创公司的数据科学家花了 11 天才找到训练不稳定的根因——原来是错误设置的 `pin_memory=True` 标志与自定义 DataLoader 中的竞争条件共同导致的。另一个团队花了三周时间定位一个特征存储 bug：由于时区处理导致时间戳连接出现差一天的错误，模型一直在用昨天的特征预测今天的结果。在高级工程师层面调试 ML 流水线，按全成本计算每天约花费 5,000-10,000 元工程师时间。

COCO 充当调试伙伴，将系统化诊断框架应用于 ML 特定的故障模式。工作流程如下：

1. **精确描述故障症状。** 粘贴错误信息、损失曲线（文本或描述）、指标轨迹，以及问题开始出现的背景（代码变更后、数据更新后、依赖升级后、基础设施迁移后）。
2. **分享技术栈配置。** 包括框架版本（PyTorch 2.x、TensorFlow、scikit-learn）、硬件（GPU 类型、多 GPU 设置）、编排工具（Airflow、Prefect、Kubeflow）和数据基础设施（特征存储、数据湖格式）。
3. **COCO 生成按优先级排列的诊断清单。** 根据症状模式识别最可能的根因类别，给出结构化的调查路径——最可能的原因排在前面，并针对每个假设给出具体的检验步骤。
4. **粘贴中间诊断输出。** 随着检验推进，分享发现的内容——梯度范数、内存剖析、中间张量统计——COCO 据此细化假设。
5. **获取附带实现代码的修复建议。** 确定根因后，COCO 提供修正后的代码、配置变更或数据流水线修复方案，并附上解释。

使用 COCO 进行 ML 调试的团队报告，流水线问题的平均解决时间缩短 65%，在以往需要升级给高级工程师处理的复杂多系统 bug 上收益最为显著。

**受益角色：**

- **数据科学家**：遭遇无法立即诊断的训练失败、指标异常或流水线错误
- **ML 工程师**：维护生产训练流水线，需要对事故进行快速根因分析
- **初级 ML 从业者**：缺乏识别常见 ML 故障模式（梯度消失、数据泄漏、预处理 bug）的模式识别经验
- **研究工程师**：实现新颖架构时需要帮助调试新模型设计中的训练不稳定性

---

## 实用提示词

**提示词 1 — 训练损失异常诊断**
```
我的 [模型类型] 模型训练出现了意外行为，需要帮助诊断根本原因。

框架：[PyTorch/TensorFlow/JAX] 版本 [版本号]
硬件：[GPU类型，单/多 GPU]
数据集：[描述，规模]
架构：[简要描述]

症状：[精确描述——如"损失在 3 轮后正常下降，然后突然飙升至 NaN"、"训练损失下降但验证损失从第 1 轮起就上升"、"损失剧烈振荡无法收敛"]

损失曲线（最近 10 轮）：
训练损失：[数值]
验证损失：[数值]

优化器：[类型，学习率，调度]
批量大小：[N]
梯度裁剪：[是/否，如是请注明阈值]

问题出现前的最近变更：[列出所有变更]

请给我按可能性排序的根因列表，并针对每个假设给出具体的诊断命令/代码。
```

**提示词 2 — 数据流水线 Bug 排查**
```
我怀疑数据流水线存在 bug 正在破坏训练数据。模型性能出乎意料地差，但我已排除架构和超参数问题。

流水线技术栈：[Airflow/Prefect/dbt/Spark，简要描述]
数据存储：[BigQuery/S3/Delta Lake/PostgreSQL]
特征工程：[Pandas/PySpark/dbt 转换]

提示数据问题的症状：
- [症状1，如"特征 X 的重要性远高于业务逻辑所预期"]
- [症状2，如"模型在最近 2 个月的数据上性能急剧下降"]
- [症状3，如"验证 AUC 为 0.95 但生产 AUC 为 0.62"]

流水线代码（最可疑的部分）：
```python
[粘贴相关流水线代码]
```

请引导我：(1) 应该运行哪些数据完整性检查，(2) 数据损坏最可能发生在流水线的哪个位置，(3) 如何添加监控/断言以在未来捕获此类 bug。
```

**提示词 3 — PyTorch 特定训练 Bug**
```
我正在调试 PyTorch 模型的训练问题。完整上下文如下：

模型架构：[描述或粘贴模型定义]
训练循环摘要：[描述关键组件]

错误或症状：
[粘贴精确的错误信息或描述症状]

堆栈跟踪（如有）：
[粘贴堆栈跟踪]

环境：
- PyTorch 版本：[版本]
- CUDA 版本：[版本]
- 使用：[DataParallel/DistributedDataParallel/单 GPU]
- 混合精度：[是/否，是否使用 amp.autocast？]
- 梯度检查点：[是/否]

已经尝试过的方法：[列出]

请诊断最可能的原因并给出修正后的代码。
```

**提示词 4 — Airflow ML 流水线 DAG 调试**
```
我的 Airflow ML 训练 DAG 出现故障，需要帮助调试。

Airflow 版本：[版本]
DAG 结构：[描述任务序列——数据提取 → 预处理 → 训练 → 评估 → 模型注册]

故障详情：
- 失败的任务：[任务名称]
- 错误信息：[粘贴错误]
- 是持续失败还是间歇性失败？[回答]
- 什么时候开始失败的？[如"升级 sklearn 从 1.2 到 1.4 之后"/"更换数据源之后"]

相关任务代码：
```python
[粘贴失败任务代码]
```

这种特定失败模式最可能的原因是什么？应该优先检查什么？
```

**提示词 5 — 可重现性和非确定性调试**
```
我的 ML 实验无法重现——相同代码运行两次得到不同结果，导致无法可靠地对比实验。

框架：[框架 + 版本]
硬件：[GPU 类型]

已设置的内容：
```python
[粘贴当前的随机种子设置代码]
```

观察到的现象：
- [如"完全相同的运行之间 AUC 相差约 2%"]
- [如"只在多 GPU 设置下出现非确定性"]
- [如"DataLoader 的 worker 似乎是根源"]

请识别我的设置中所有潜在的非确定性来源（框架算子、DataLoader、数据增强、分布式训练、自定义 CUDA 核等），并给我一份完整的可重现性核查清单，附带修复每个来源的代码。
```
