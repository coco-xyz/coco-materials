# 用例 #402：AI 数据治理政策撰写器

**角色**：数据科学家 / 机器学习工程师 | **行业**：SaaS、科技、企业 | **任务**：合规、数据治理、政策制定

---

## 详细介绍

**痛点：从业者忽视的政策**

大多数组织的数据治理政策由两种失败模式之一产生。第一种是法律和合规团队在没有有意义的技术投入的情况下编写政策——生成的文件准确描述了监管要求，但规定了技术上不可能的控制措施，省略了从业者实施这些措施所需的操作细节，或使用了在实际数据管道背景下无法解读的监管语言。一个说"个人身份信息必须在静止状态和传输中加密"的政策，对于数据工程师在决定是否在 dbt 转换中对用户 ID 进行哈希处理、是否在 Snowflake 中应用列级加密、是否从模型训练数据集中删除 PII 或在数据使用协议下保留 PII，或者如何处理意外捕获用户行为的日志文件时，提供零指导。政策声明与所需实施决策之间的差距如此之大，以至于从业者用自己的判断来填补——因人而异，很少有文档记录，并产生审计人员在审查期间标记的不一致做法。

第二种失败模式是数据团队编写自己的事实上的政策——通过随时间积累但从未编码化的实践。一位高级数据科学家为匿名化训练数据开发了一种模式；它成为团队的非正式标准。一位数据工程师根据存储成本考虑而非政策设置原始事件日志的保留计划。对数据仓库中敏感表的访问控制是临时授予的，权限集从未经过最小权限合规性审查。这些非正式做法产生了认为自己有良好数据卫生的团队，因为团队中的高级人员以正确的方式做事，但实际上没有可强制执行的标准、没有审计跟踪，也没有机制让新工程师接受一致做法的培训。

机器学习的特定领域产生了传统法律/合规团队和大多数数据治理框架都无法应对的治理挑战。训练数据治理与运营数据治理根本不同：对运营用途正确匿名化的训练数据仍可能通过模型输出暴露 PII（成员推断攻击、属性推断），这意味着生产数据的政策框架不能简单地扩展以覆盖 ML。同样，受监管行业（金融服务、医疗保健、保险）的模型版本控制和数据来源要求远超一般数据治理框架所规定的——模型卡片、训练数据来源、特征定义和性能监控文档都是治理工件，在大多数组织中没有标准模板，没有明确的政策所有者。

监管格局也变得更加严格。GDPR 第 22 条关于自动决策的限制、扩展到训练数据的 CCPA 数据删除要求、欧盟 AI 法案对高风险 AI 系统文档的要求，以及特定行业法规（金融机构的 SR 11-7 模型风险管理指南、去识别化健康数据的 HIPAA 安全港要求）都创建了位于数据法律和 ML 实践交叉点的合规义务。很少有组织拥有解决这一交叉点的治理政策——让数据科学家和 ML 工程师在没有组织指导的情况下做出个人合规决策，且不了解这些决策带来的法律风险。

**COCO 如何解决这一问题**

COCO 弥合法律要求和技术实施之间的差距——以精确、可操作的语言起草数据治理政策，法律审查员和工程从业者都能理解、实施和验证。

1. **数据分类政策起草**：COCO 编写具有精确、可枚举标准的数据分类框架——使数据工程师和科学家能够在不需要对每个决策进行合规性审查的情况下正确分类新数据资产。
   - 定义分类层级（公开、内部、保密、受限），并提供与组织数据类型相关的具体示例
   - 规定每个层级适用的治理控制：加密要求、访问控制标准、保留限制和批准的处理位置

2. **ML 管道的 PII 处理政策**：COCO 起草针对 PII 的治理规则，涵盖完整的 ML 生命周期——从数据摄取到特征工程、训练数据构建、模型训练、推断记录和模型退役。
   - 涵盖技术控制：标记化、k 匿名性、差分隐私、数据使用协议，以及每种方法何时充分、何时不充分的条件
   - 解决 ML 特定风险：训练数据重新识别风险、模型反转攻击，以及从输出重新创建 PII 的下游推断记录

3. **访问控制政策设计**：COCO 为数据环境设计基于角色的访问控制（RBAC）和基于属性的访问控制（ABAC）政策——规定谁可以在什么条件下访问什么数据，以及审批工作流和定期审查要求。
   - 定义数据仓库环境（Snowflake、BigQuery、Databricks）的访问层级，并提供具体的行级安全性和列屏蔽指导
   - 规定紧急访问场景的应急程序和审计跟踪要求

4. **数据保留和删除政策**：COCO 起草平衡监管最低要求、商业价值和存储经济性的保留计划——提供针对训练数据、模型工件和推断日志的具体、可实施的删除程序。
   - 涵盖列式仓库、分区表和 ML 特征存储中删除的操作复杂性
   - 解决在训练数据和派生模型输出背景下的 GDPR/CCPA 被遗忘权要求

5. **ML 模型治理政策**：COCO 编写模型治理框架，定义 ML 模型的开发、审查、批准、部署、监控和退役程序——特别是针对受监管的使用场景。
   - 涵盖模型风险层级、审批关卡、每个关卡的文档要求，以及触发模型审查或退役的条件
   - 与金融服务的 SR 11-7 模型风险管理指南或同等行业特定框架保持一致

6. **审计跟踪和文档要求**：COCO 规定数据处理活动的最低审计跟踪和文档标准——定义必须记录、保留和可供监管审查的内容。
   - 使用现代编排工具（Airflow、dbt、Prefect）定义数据管道的数据来源文档要求
   - 规定每个生命周期阶段所需的模型文档工件：模型卡片、数据表、性能基准和偏见评估

**可量化的成果**

- **政策合规率**：数据工程师和科学家在没有合规性审查的情况下正确对新资产应用数据分类的比例 → 基线 34% → 可实施政策部署后 71%
- **审计发现减少**：每个内部审计周期的关键数据治理发现 → 平均 8.3 个发现 → 带技术实施指导的政策更新后 2.1 个
- **访问控制卫生**：过度特权的数据仓库访问授予（用户访问的数据超过其角色所需）→ 67% 的账户 → RBAC 政策实施后 19%
- **PII 事件减少**：ML 管道中每季度意外 PII 暴露事件 → 2.4 个事件 → ML 特定 PII 处理政策部署后 0.4 个
- **治理文档覆盖率**：生产中具有完整治理文档的 ML 模型 → 基线 8% → 带强制性工件的模型治理政策后 61%

**受益角色**

- **数据科学家**：获得 PII 处理、训练数据治理和模型文档的清晰、可实施指导——用可强制执行的组织标准取代个人判断
- **数据工程师**：使用访问控制和保留政策，精确指定在管道工具中实施什么控制，消除产生不一致做法的模糊性
- **首席数据官**：使用 COCO 起草的政策作为满足董事会级风险要求并通过监管审查的正式治理框架的基础
- **法律和合规团队**：获得技术上可信的政策文件，他们可以验证监管合规性，而无需自己撰写技术实施规范

---

## 实用提示词

**提示词 1：数据分类框架**
```
帮我为我们组织的数据环境起草实用的数据分类政策。

组织背景：
- 行业：[行业——例如"B2B SaaS，医疗科技"]
- 我们必须遵守的关键法规：[GDPR / CCPA / HIPAA / SOC 2 / 其他]
- 主要数据系统：[数据仓库 / 数据库 / 云存储——例如"Snowflake、S3、PostgreSQL"]
- 我们处理的敏感数据类型：[例如"客户 PII、金融交易数据、健康记录、行为事件日志"]
- 团队规模和技术成熟度：[例如"25 名工程师，高级和初级混合"]

起草一个数据分类政策，包含：
1. 分类层级（建议适合我们背景的层级）及通俗易懂的定义
2. 每个层级：来自我们特定数据类型的具体示例，使工程师能够自行分类新资产
3. 每个层级所需的控制：加密标准、访问控制方法、批准的存储位置、保留限制
4. 分类决策树：从业者可用于在 2 分钟内对新数据集进行分类的流程图式指南
5. 治理要求：谁批准层级分配、如何解决冲突、如何处理层级变更
6. 我们特定平台（Snowflake、S3、PostgreSQL）的实施说明
```

**提示词 2：ML 管道的 PII 处理政策**
```
我需要一个政策来管理我们整个机器学习生命周期中 PII 的处理方式——从原始数据到训练、推断和模型退役。

组织背景：
- 我们处理的 PII 类型：[例如"用户电子邮件、带用户 ID 的行为事件日志、支持对话记录"]
- 涉及 PII 的 ML 使用场景：[例如"流失预测、内容推荐、客户分群"]
- 适用法规：[GDPR / CCPA / HIPAA / 其他]
- 当前实践（描述您今天实际做什么）：[当前处理方法]
- 您意识到的差距或风险：[已知问题]

起草一个 ML 管道的 PII 处理政策，涵盖：
1. ML 中 PII 的许可使用（附条件和审批要求）
2. 按 PII 类型和 ML 使用场景所需的去识别化方法（标记化、假名化、k 匿名性、差分隐私——每种方法的技术规范）
3. 训练数据治理：哪些 PII 可以出现在训练集中，哪些必须删除，如何记录训练数据组成
4. 推断记录：哪些 PII 可以出现在模型输入/输出日志中以及保留多长时间
5. 重新识别风险评估：评估匿名化训练数据是否可从模型输出重新识别的要求
6. 删除程序：当 PII 嵌入训练数据或模型权重时如何处理被遗忘权请求
7. 政策违规：构成违规的内容、报告程序和补救要求
```

**提示词 3：数据访问控制政策**
```
帮我为我们的数据仓库和分析环境编写数据访问控制政策。

环境：
- 主要数据平台：[Snowflake / BigQuery / Databricks / Redshift / 其他]
- 辅助系统：[列出其他有敏感数据的系统]
- 数据用户大致数量：[N]
- 访问数据的关键角色：[列出角色——例如"数据科学家、分析师、工程师、财务团队、高管仪表盘"]
- 当前状态：[描述当前如何管理访问——临时、任何现有 RBAC？]
- 需要特殊控制的敏感数据类型：[PII、金融、健康、其他]

起草一个访问控制政策，涵盖：
1. 角色定义：定义访问层级（例如分析师只读、数据科学家宽泛读取、工程师读写、管理员）及每个层级的具体数据访问范围
2. 访问配置流程：如何请求、批准和配置访问（审批链、SLA、文档要求）
3. 最小权限要求：如何将访问范围限定在最少必要数据，以及定期审查要求
4. 列级和行级安全性：敏感列的具体控制（PII 屏蔽、按数据敏感性或用户地区的行过滤）
5. 访问审查节奏：访问权限多久审查一次以及谁负责
6. 紧急（应急）访问：访问受限数据的紧急程序，带自动审计跟踪要求
7. 离职处理：员工离职或换岗时的访问撤销要求和时间表
```

**提示词 4：ML 模型治理政策**
```
帮我起草一个 ML 模型治理政策，定义我们组织中模型的开发、审查、批准、部署、监控和退役方式。

组织背景：
- 行业：[行业]
- 监管背景：[任何模型风险法规——例如"银行业的 SR 11-7，欧盟 AI 法案，医疗保健模型的 HIPAA"]
- 我们部署的模型类型：[例如"流失预测、欺诈检测、内容排名、NLP 分类器"]
- 当前治理差距：[您知道缺失的内容]
- 团队结构：[谁构建模型、谁批准、谁监控]

起草一个模型治理政策，涵盖：
1. 模型风险分层：将模型分类为低、中或高风险的标准（基于决策影响、自动化程度、受影响人群）
2. 按风险层级的开发要求：模型可提交审查前的文档、测试和验证要求
3. 模型审查和批准流程：谁审查、评估什么、批准标准、分歧升级
4. 所需文档工件：模型卡片模板、训练数据数据表、性能基准报告、偏见评估
5. 部署关卡：模型部署到生产之前必须完成的内容
6. 监控要求：按风险层级的性能监控、数据漂移检测和警报阈值
7. 模型退役：触发模型退役的条件、文档要求，以及退役模型的数据删除程序
```

**提示词 5：数据保留和删除政策**
```
帮我起草一个既符合法律合规又可在我们数据基础设施中技术实施的数据保留和删除政策。

组织背景：
- 适用法规：[GDPR / CCPA / HIPAA / 行业特定 / 其他]
- 关键数据类型及其当前保留做法：[列出数据类型和当前保留——例如"原始事件日志：无限期保留，客户 PII：保留至账户删除"]
- 数据基础设施：[数据仓库、对象存储、数据库——例如"BigQuery、GCS、PostgreSQL、Kafka"]
- 需要治理的 ML 工件：[训练数据集、模型权重、特征存储、推断日志]
- 已知合规差距：[您知道存在的问题]

起草一个保留和删除政策，涵盖：
1. 按数据类型的保留计划：为每个数据类别规定最短和最长保留期，并说明业务或法律依据
2. 保留实施：如何在我们特定基础设施中实施保留计划（BigQuery 中基于分区的删除、GCS 中的生命周期策略、数据库中的 TTL）
3. 被遗忘权程序：处理删除请求的分步程序，包括如何识别用户数据可能存在的所有位置
4. ML 数据删除复杂性：如何处理用于模型训练的数据的删除请求（选项：不包含已删除数据的重训练、模型退役、附法律依据的有文档例外）
5. 审计跟踪要求：哪些删除事件必须记录、保留并可供监管审查
6. 保留政策执行：如何检测和补救保留政策违规（数据超过政策允许年限）
7. 政策审查节奏：随着法规变化，保留计划多久审查和更新一次
```

---
