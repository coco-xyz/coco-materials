# #395 — AI ML 实验追踪器

**角色**：数据科学家
**行业**：SaaS / 科技
**任务**：监控
**标识**：`ai-ml-experiment-tracker`

---

## 简介

机器学习领域的可重现性危机从根本上说不是技术问题，而是文档问题。MLflow、Weights & Biases 和 Neptune 都为指标、参数和制品的日志记录提供了优秀的基础设施。然而在实践中，数据科学家持续低效利用这些工具：实验运行时缺少参数日志、假设动机从未被写下来，停止某条实验路线的决定从未被解释。六个月后新团队成员加入，问"为什么我们尝试了随机森林但后来放弃了？"，没人能回答。

更深层的问题在于，实验追踪需要同时记录"你做了什么"和"你为什么这样做"——即实验叙事。MLflow 能跟踪你以特定超参数运行了 47 个实验，最高 AUC 达到 0.847。但它无法告诉你：实验 23-31 在探索 SMOTE 过采样是否有助于处理类别不平衡（结果是没有），实验 32-40 在相同特征集下测试 LightGBM 与 XGBoost（LightGBM 速度更快且性能相当），或者在实验 35 时将主要指标从 AUC 切换到 F1，是由于产品对精确率-召回率权衡的讨论驱动的。这个叙事才是将运行列表转化为机构知识的关键。

缺乏这种叙事会导致几种代价高昂的情况。首先，研究人员重复已经运行过的实验，浪费算力资源——2023 年的一项调查发现，ML 团队由于追踪不善重复了 23% 的实验。其次，当模型在生产中失败时，无法重建确切的实验背景使根因分析几乎不可能完成。第三，当监管机构或审计人员问"你如何选择这个模型时？"，团队无法提供关于决策过程的清晰陈述。

COCO 充当你 MLflow 或 W&B 基础设施之上的实验叙事层。工作流程如下：

1. **按常规在追踪工具中记录实验。** COCO 是对现有追踪基础设施的补充，而非替代。
2. **向 COCO 总结实验会话。** 在工作会话或实验块结束时，描述你尝试了什么、结果如何，以及你困惑的地方或接下来的计划。
3. **COCO 生成结构化实验日志条目。** 将你的叙述格式化为可重现的实验摘要：假设陈述、运行的实验（附运行 ID）、结果、得出的结论、计划的后续步骤。
4. **COCO 跨会话综合。** 当你分享多个会话日志时，它识别模式——哪些方法正在收敛、哪些已经穷尽、哪里出现了收益递减——并生成实验总结报告。
5. **获得实验评审建议。** COCO 根据已尝试内容识别应该运行的实验，建议剩余调查的优先级顺序，并在当前方法看起来缺少重要基线时发出警告。

结合 MLflow 使用 COCO 的团队报告，实验可重现性评分提升 78%（以团队成员能否仅凭文档重建实验决策来衡量），重复实验减少 45%。

**受益角色：**

- **数据科学家**：进行大量实验但难以维护清晰、可重现的过程叙事文档
- **ML 优先公司的研究团队**：实验卫生直接影响研究速度和机构知识积累
- **ML 团队负责人**：需要在批准模型投产前评审并理解其背后的实验过程
- **新团队成员**：需要快速了解所接手模型的实验历史

---

## 实用提示词

**提示词 1 — 每日实验日志条目**
```
我需要为今天的工作写一个结构化实验日志条目。以下是我所做工作的自由描述：

项目：[项目名称]
模型目标：[要构建的内容]
MLflow 实验 ID / W&B 项目：[ID 或名称]

今天的工作：
[自由描述尝试的内容——如"测试了 SMOTE 与不进行过采样，尝试了学习率 1e-3 和 1e-4，使用 lag-7 和 lag-30 特征进行特征工程，发现滞后特征导致过拟合"]

今天最佳运行指标：[粘贴运行 ID 和指标]
最有趣的发现：[描述]
什么没有效果：[描述]
待解决的问题：[列表]
明天的计划：[描述]

请将其格式化为结构化实验日志条目，包含：假设、运行的实验（附运行 ID）、观察结果、结论和后续步骤。
```

**提示词 2 — 实验阶段总结**
```
我已完成一个实验阶段，需要总结所学内容。以下是过去 [N 周] 的会话日志：

[粘贴或描述会话日志1]
[粘贴或描述会话日志2]
[等]

或者：以下是本阶段排名前 20 的 MLflow 运行：
| 运行 ID | 模型 | 关键超参数 | 验证 AUC | 备注 |
|---------|------|-----------|---------|------|
[粘贴表格]

请综合：(1) 探索了哪些方法，(2) 每种方法的关键发现，(3) 哪些可以认为已关闭/已穷尽，(4) 哪些有待探索，(5) 当前最优方法及原因，(6) 推荐的下一实验阶段计划。
```

**提示词 3 — 下一阶段实验设计**
```
我在 [项目] 上已经运行了 [N 周] 实验，不确定接下来该尝试什么。当前状态：

目前最佳模型：[模型类型，AUC=[数值]]
目标性能：[目标 AUC 或其他指标]
性能差距：[当前值 - 目标值]

已经尝试的内容（及发现）：
1. [方法1]：[结果和结论]
2. [方法2]：[结果和结论]
3. [方法3]：[结果和结论]

可用资源：[GPU 小时数，数据量，团队规模]
截止日期：[日期]

根据此实验历史，请建议：(1) 接下来优先级最高的 3 个实验，(2) 鉴于已尝试内容投入产出比低的实验，(3) 是否应该转向根本不同的方法，(4) 如何在截止日期约束下确定优先级。
```

**提示词 4 — 模型选择决策文档**
```
我需要为 [项目] 模型的选择决策写一份文档，格式应能向利益相关方和未来团队成员解释决策依据。

考虑的实验：[N 周内共 N 个实验]
最终候选：
- 模型 A：[描述]，AUC=[值]，F1=[值]，延迟=[值]ms
- 模型 B：[描述]，AUC=[值]，F1=[值]，延迟=[值]ms
- 模型 C：[描述]，AUC=[值]，F1=[值]，延迟=[值]ms

应用的选择标准：
1. [标准1，权重]
2. [标准2，权重]
3. [标准3，权重]

选择的模型：[模型]
接受的关键权衡：[描述]

请撰写一份模型选择决策文档，内容包括：评估标准及选择原因、候选模型的透明对比、决策及其依据、权衡确认，以及可作为未来审查审计记录的格式。
```

**提示词 5 — 重现过去的实验**
```
我需要重现并理解 [N 个月前] 由 [原作者/"前团队成员"] 运行的实验。现有文档不完整。

现有资料：
- MLflow 运行 ID：[运行 ID]
- 已记录参数：[粘贴 MLflow 参数]
- 已记录指标：[粘贴指标]
- Git 提交哈希（如有）：[哈希]
- 任何备注：[粘贴备注（如存在）]

缺失或不清晰的内容：
- [差距1，如"未记录训练数据版本"]
- [差距2，如"不清楚特征工程是在训练/测试集划分前还是划分后应用的"]
- [差距3]

请帮我：(1) 根据现有证据重建最可能的实验设置，(2) 识别完全重现此运行需要回答的问题，(3) 列出验证重现是否匹配原始结果的检查项，(4) 为此实验撰写文档，以防止将来出现同样的歧义。
```
